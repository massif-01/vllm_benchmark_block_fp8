# vLLM Block FP8 å†…æ ¸è°ƒä¼˜å·¥å…·

> ğŸŒ [English](README.md) | [ä¸­æ–‡](README_zh.md)

vLLM çš„è‡ªåŠ¨åŒ– Triton w8a8 block FP8 å†…æ ¸è°ƒä¼˜å·¥å…·ã€‚è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ¶æ„å¹¶ä¼˜åŒ–å†…æ ¸é…ç½®ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¯ **æ¨¡å‹è‡ªåŠ¨æ£€æµ‹**: è‡ªåŠ¨ä» HuggingFace æ¨¡å‹é…ç½®ä¸­æå–æƒé‡å½¢çŠ¶
- ğŸ”„ **å¤š GPU æ”¯æŒ**: è·¨å¤šä¸ª GPU å¹¶è¡Œè°ƒä¼˜ï¼Œæ›´å¿«è·å¾—ç»“æœ
- ğŸ“Š **çµæ´»é…ç½®**: æ”¯æŒä¸åŒçš„ TP å¤§å°ã€å—å¤§å°å’Œæ‰¹æ¬¡å¤§å°
- ğŸš€ **é¢„è®¾è„šæœ¬**: æµè¡Œæ¨¡å‹çš„å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆQwen3ã€DeepSeek-V3ï¼‰
- âœ… **ç¯å¢ƒæ£€æŸ¥**: é¢„æ£€æŸ¥ç¡®ä¿ç¯å¢ƒå‡†å¤‡å°±ç»ª

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒæ£€æŸ¥

```bash
bash scripts/environment_check.sh
```

### 2. å•æ¨¡å‹è°ƒä¼˜

```bash
# Qwen3-Coder-30B-A3B-Instruct-FP8ï¼ˆä¼˜åŒ–é¢„è®¾ï¼‰
bash scripts/tune_qwen3_coder.sh

# Qwen3 æ¨¡å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹å½¢çŠ¶ï¼‰
bash scripts/tune_qwen3.sh Qwen/Qwen3-MoE-A14.5B-Chat 4

# DeepSeek-V3ï¼ˆä½¿ç”¨é»˜è®¤å½¢çŠ¶ï¼‰
bash scripts/tune_deepseek_v3.sh 8

# è‡ªå®šä¹‰æ¨¡å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹å½¢çŠ¶ï¼‰
bash scripts/tune_custom.sh your-model-name 2
```

### 3. æˆ–ç›´æ¥ä½¿ç”¨ Python

```bash
# Qwen3-Coder-30B-A3B-Instruct-FP8ï¼ˆä½¿ç”¨è‡ªåŠ¨æ£€æµ‹ï¼‰
python benchmark_w8a8_block_fp8.py --model Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8 --tp-size 4 --input-type fp8 --trust-remote-code

# Qwen3 æ¨¡å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹å½¢çŠ¶ï¼‰
python benchmark_w8a8_block_fp8.py --model Qwen/Qwen3-MoE-A14.5B-Chat --tp-size 4 --input-type fp8

# DeepSeek-V3ï¼ˆé»˜è®¤å½¢çŠ¶ï¼‰
python benchmark_w8a8_block_fp8.py --tp-size 8 --input-type fp8
```

## é…ç½®è¯´æ˜

### å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--model` | HuggingFace æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆè‡ªåŠ¨æ£€æµ‹å½¢çŠ¶ï¼‰ | Noneï¼ˆä½¿ç”¨ DeepSeek-V3ï¼‰ |
| `--tp-size` | å¼ é‡å¹¶è¡Œå¤§å° | `8` |
| `--input-type` | è¾“å…¥é‡åŒ–ç±»å‹ | `fp8` |
| `--out-dtype` | è¾“å‡ºæ•°æ®ç±»å‹ | `float16` |
| `--block-n` | é‡åŒ–çš„å—å¤§å° N | `128` |
| `--block-k` | é‡åŒ–çš„å—å¤§å° K | `128` |
| `--batch-size` | è¦æµ‹è¯•çš„å•ä¸ªæ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼šæµ‹è¯•æ‰€æœ‰ï¼‰ | None |
| `--save-path` | ä¿å­˜è°ƒä¼˜é…ç½®çš„ç›®å½• | `./tuned_configs` |
| `--trust-remote-code` | åŠ è½½æ¨¡å‹æ—¶ä¿¡ä»»è¿œç¨‹ä»£ç  | False |

## æ”¯æŒçš„æ¨¡å‹

å·¥å…·è‡ªåŠ¨æ£€æµ‹ä»¥ä¸‹æ¨¡å‹çš„æƒé‡å½¢çŠ¶ï¼š

- **Qwen3 ç³»åˆ—**: Qwen3-MoEã€Qwen3-Next æ¨¡å‹
- **DeepSeek-V3**: å†…ç½®é»˜è®¤å½¢çŠ¶
- **é€šç”¨ Transformer**: ä» `hidden_size` å’Œ `intermediate_size` è‡ªåŠ¨æ£€æµ‹

å¯¹äºä¸æ”¯æŒçš„æ¨¡å‹ï¼Œå·¥å…·ä¼šå›é€€åˆ° DeepSeek-V3 é»˜è®¤å½¢çŠ¶ã€‚

## è¾“å‡º

è°ƒä¼˜åçš„é…ç½®ä¿å­˜ä¸º JSON æ–‡ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```
N={N},K={K},device_name={device_name},dtype=fp8_w8a8,block_shape=[{block_n},{block_k}].json
```

æ¯ä¸ªæ–‡ä»¶åŒ…å«ä¸åŒæ‰¹æ¬¡å¤§å°çš„æœ€ä¼˜é…ç½®ï¼š

```json
{
  "1": { "BLOCK_SIZE_M": 64, "BLOCK_SIZE_N": 128, ... },
  "64": { "BLOCK_SIZE_M": 128, "BLOCK_SIZE_N": 256, ... },
  ...
}
```

### å¤åˆ¶é…ç½®åˆ° vLLM

è°ƒä¼˜åï¼Œå°†ç”Ÿæˆçš„é…ç½®å¤åˆ¶åˆ° vLLMï¼š

```bash
cp tuned_configs/*.json /path/to/vllm/model_executor/layers/quantization/utils/configs/
```

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä½¿ç”¨ TP=4 è°ƒä¼˜ Qwen3-Coder-30B-A3B-Instruct-FP8

```bash
bash scripts/tune_qwen3_coder.sh Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8 4
```

### ç¤ºä¾‹ 1b: ä½¿ç”¨ TP=4 è°ƒä¼˜ Qwen3-MoE

```bash
bash scripts/tune_qwen3.sh Qwen/Qwen3-MoE-A14.5B-Chat 4
```

### ç¤ºä¾‹ 2: æ‰¹é‡è°ƒä¼˜å¤šä¸ªæ¨¡å‹

```bash
bash examples/tune_qwen3_models.sh
```

### ç¤ºä¾‹ 3: è‡ªå®šä¹‰å—å¤§å°

```bash
python benchmark_w8a8_block_fp8.py \
    --model your-model \
    --tp-size 2 \
    --block-n 64 \
    --block-k 128 \
    --input-type fp8
```

## é¡¹ç›®ç»“æ„

```
vllm_benchmark_block_fp8/
â”œâ”€â”€ README.md                      # è‹±æ–‡æ–‡æ¡£
â”œâ”€â”€ README_zh.md                   # ä¸­æ–‡æ–‡æ¡£
â”œâ”€â”€ benchmark_w8a8_block_fp8.py   # ä¸»è°ƒä¼˜è„šæœ¬
â”œâ”€â”€ scripts/                       # è¾…åŠ©è„šæœ¬
â”‚   â”œâ”€â”€ environment_check.sh      # ç¯å¢ƒæ£€æŸ¥
â”‚   â”œâ”€â”€ tune_qwen3_coder.sh      # Qwen3-Coder é¢„è®¾ï¼ˆå·²ä¼˜åŒ–ï¼‰
â”‚   â”œâ”€â”€ tune_qwen3.sh             # Qwen3 é¢„è®¾
â”‚   â”œâ”€â”€ tune_deepseek_v3.sh       # DeepSeek-V3 é¢„è®¾
â”‚   â””â”€â”€ tune_custom.sh            # è‡ªå®šä¹‰æ¨¡å‹é¢„è®¾
â”œâ”€â”€ configs/                       # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ model_shapes.json         # æ¨¡å‹å½¢çŠ¶å‚è€ƒ
â””â”€â”€ examples/                      # ç¤ºä¾‹è„šæœ¬
    â””â”€â”€ tune_qwen3_models.sh     # æ‰¹é‡è°ƒä¼˜ç¤ºä¾‹
```

## å‰ç½®è¦æ±‚

- Python 3.8+
- æ”¯æŒ CUDA çš„ PyTorch
- å·²å®‰è£… vLLMï¼ˆå¿…é¡»åœ¨ Python è·¯å¾„ä¸­ï¼‰
- å…¼å®¹ CUDA çš„ GPU
- å¿…éœ€çš„ vLLM æ¨¡å—ï¼š`fp8_utils`ã€`triton_utils`ã€`transformers_utils`

## è®¸å¯è¯

Apache-2.0 è®¸å¯è¯

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤ Issues å’Œ Pull Requestsã€‚

---

â­ **å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼**

